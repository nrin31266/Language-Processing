# src/services/speech_to_text_service.py

import asyncio
import os

import librosa
import torch
import whisperx

from src import dto
from src.errors.base_exception import BaseException
from src.errors.base_error_code import BaseErrorCode

# -------------------
# 1. Device + ASR model
# -------------------
device = "cuda" if torch.cuda.is_available() else "cpu"
compute_type = "float16" if device == "cuda" else "float32"

print(f"üîÑ [WhisperX] Loading ASR model (base.en) on {device} ({compute_type})...")
with torch.no_grad():
  whisper_model = whisperx.load_model(
      "base.en",
      device=device,
      compute_type=compute_type,
  )
print("‚ú® [WhisperX] ASR model loaded successfully!")

# -------------------
# 2. Align model cache (per language)
# -------------------

_align_model_cache: dict[str, tuple[object, dict]] = {}


def _get_align_model(language_code: str) -> tuple[object, dict]:
    """
    Load align model theo language_code, nh∆∞ng ch·ªâ load 1 l·∫ßn r·ªìi cache l·∫°i.
    ƒêi·ªÅu n√†y tr√°nh vi·ªác m·ªói l·∫ßn transcribe l·∫°i load model m·ªõi ‚Üí ph√¨nh RAM.
    """
    if not language_code:
        language_code = "en"

    if language_code in _align_model_cache:
        return _align_model_cache[language_code]

    print(f"üîÑ [WhisperX] Loading align model for language={language_code} on {device}...")
    with torch.no_grad():
        align_model, metadata = whisperx.load_align_model(
            language_code=language_code,
            device=device,
        )
    _align_model_cache[language_code] = (align_model, metadata)
    print(f"‚ú® [WhisperX] Align model for {language_code} loaded & cached.")
    return align_model, metadata


# =========================
#  SYNC IMPLEMENTATION
# =========================

def _get_audio_duration_sync(path: str) -> float:
    if not os.path.exists(path):
        raise BaseException(BaseErrorCode.NOT_FOUND, f"File not found: {path}")
    try:
        # librosa.load ƒë·ªçc to√†n b·ªô file v√†o RAM, nh∆∞ng ch·ªâ ƒë·ªÉ l·∫•y duration.
        # N·∫øu mu·ªën ti·∫øt ki·ªám RAM h∆°n n·ªØa, c√≥ th·ªÉ d√πng soundfile.info ho·∫∑c ffprobe sau n√†y.
        y, sr = librosa.load(path, sr=None)
        return librosa.get_duration(y=y, sr=sr)
    except Exception:
        raise BaseException(
            BaseErrorCode.INVALID_AUDIO_FILE,
            f"Invalid audio file: {path}",
        )


def _transcribe_sync(audio_path: str):
    """
    H√†m sync g·ªçi WhisperX ƒë·ªÉ transcribe + align.
    D√πng n·ªôi b·ªô, b·ªçc b·ªüi async transcribe().
    """
    with torch.no_grad():
        # 1. WhisperX transcription
        result = whisper_model.transcribe(audio_path, batch_size=4)

        # 2. WhisperX alignment (d√πng model cache)
        language_code = result.get("language") or "en"
        align_model, metadata = _get_align_model(language_code)

        aligned = whisperx.align(
            result["segments"],
            align_model,
            metadata,
            audio_path,
            device,
        )

    # üßπ Ch·ªâ x√≥a ƒë√∫ng tr∆∞·ªùng 'word_segments'
    if isinstance(aligned, dict):
        aligned.pop("word_segments", None)

    return aligned


# =========================
#  ASYNC WRAPPERS
# =========================

async def get_audio_duration(path: str) -> float:
    """
    Async wrapper cho vi·ªác l·∫•y duration audio.
    Ch·∫°y trong thread pool ƒë·ªÉ kh√¥ng block event loop.
    """
    return await asyncio.to_thread(_get_audio_duration_sync, path)


async def transcribe(audio_path: str):
    """
    Async wrapper cho WhisperX transcribe + align.
    Ch·∫°y trong thread pool ƒë·ªÉ kh√¥ng block event loop.
    Tr·∫£ v·ªÅ dict (aligned result).
    """
    return await asyncio.to_thread(_transcribe_sync, audio_path)
